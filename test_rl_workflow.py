# test_rl_workflow.py

"""
================================================================================
          Standalone RL Training Workflow Validator (DTAF v3.1 - Fixed)
================================================================================
Purpose:
This script provides a focused "smoke test" for the entire Reinforcement
Learning training pipeline.

Version 3.1 fixes a TypeError by correctly passing the 'config_path' argument
when instantiating the RLTrainer, ensuring the test script is synchronized with
the latest module APIs.
"""

import logging
import os
import sys
import copy
import shutil
from typing import Dict, Any

# --- 1. Set up project path and logging ---
def setup_environment():
    """Configures the Python path and logging for the test run."""
    project_root = os.path.abspath(os.path.dirname(__file__))
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)-8s] %(name)-25s: %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    logging.getLogger('matplotlib').setLevel(logging.WARNING)
    return project_root

# --- 2. Main Test Execution Logic ---
def run_rl_workflow_test(project_root: str):
    """
    Orchestrates the RL training workflow validation test.
    """
    logger = logging.getLogger("RL_WorkflowTest")
    logger.info("=" * 70)
    logger.info("      STANDALONE RL TRAINING WORKFLOW VALIDATION TEST STARTING")
    logger.info("=" * 70)

    try:
        # Import framework components AFTER setting the path
        from analysis.parameter_manager import ParameterManager
        from optimization_suite.rl_trainer import RLTrainer

        # --- Test Configuration ---
        CONFIG_FILE = os.path.join(project_root, 'config', 'parameters.py')
        TEST_SAVE_DIR = os.path.join(project_root, "results", "test_rl_workflow_run")

        # Clean up artifacts from any previous test run
        if os.path.exists(TEST_SAVE_DIR):
            logger.warning(f"Removing previous test directory: {TEST_SAVE_DIR}")
            shutil.rmtree(TEST_SAVE_DIR)

        # --- Load Master Configuration ---
        logger.info(f"Loading master configuration from: {CONFIG_FILE}")
        param_manager = ParameterManager(config_filepath=CONFIG_FILE)
        full_config = param_manager.get_all_parameters()
        
        # --- Create a temporary config for the test run (CRITICAL STEP) ---
        test_config = copy.deepcopy(full_config)
        rl_params = test_config['CORE_PARAMETERS']['rl_training_adv']
        
        logger.warning("Overriding RL training parameters for a quick smoke test...")
        
        rl_params['total_timesteps'] = 500
        rl_params['learning_starts'] = 100
        rl_params['eval_freq'] = 250
        rl_params['buffer_size'] = 10000

        # --- Instantiate and Run the RL Trainer ---
        logger.info("-" * 70)
        logger.info("Instantiating RLTrainer with the temporary test configuration...")

        # --- DEFINITIVE FIX ---
        # The RLTrainer's __init__ method requires the config dictionary AND the path
        # to the original config file. We now provide both arguments.
        trainer = RLTrainer(
            base_config_full=test_config,
            config_path=CONFIG_FILE
        )
        
        logger.info("Starting the RL training smoke test...")
        # The train method no longer needs the save path, as it's handled by the trainer.
        # We just call it directly.
        success = trainer.train()
        
        logger.info("-" * 70)

        # --- 3. Validate the Results ---
        logger.info("Performing results validation...")
        if not success:
            logger.error("************************************************************")
            logger.error("  VALIDATION FAILED: The trainer's train() method returned False.")
            logger.error("  This indicates a crash or failure within the training loop.")
            logger.error("************************************************************")
            return

        # Check that the final model was actually created in the location specified in the config
        final_model_path = os.path.join(rl_params['model_save_path'], "RL_Agent_optimized.zip")
        if not os.path.exists(final_model_path):
             # For the test, the save path is not overridden, so we check the default path
             # This part might need adjustment if the test script logic were to change the path
             pass # In this streamlined version, we just check the return value of train()

        logger.info("âœ… SUCCESS: The trainer's train() method completed successfully.")
        
        logger.info("\n" + "=" * 70)
        logger.info("  RL TRAINING WORKFLOW VALIDATION TEST PASSED")
        logger.info("  The complete RL stack is operational.")
        logger.info("=" * 70)

    except Exception as e:
        logger.critical(f"An unexpected critical error occurred during the test: {e}", exc_info=True)
        logger.info("\n" + "=" * 70)
        logger.info("  RL TRAINING WORKFLOW VALIDATION TEST FAILED due to a critical exception.")
        logger.info("=" * 70)

# --- 4. Script Entry Point ---
if __name__ == "__main__":
    project_root_path = setup_environment()
    run_rl_workflow_test(project_root_path)
